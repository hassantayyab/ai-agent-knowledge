# RAG 101: retrieval beats stuffing context (Chapter 17)

## Summary

- **RAG (Retrieval‑Augmented Generation)** improves accuracy by retrieving relevant documents and adding them to the model’s context.
- It’s the standard pattern when the model needs:
  - up-to-date information
  - private/internal knowledge
  - large corpora that don’t fit in context windows
- A basic RAG loop:
  1. embed documents
  2. store embeddings in a vector database
  3. embed the query
  4. retrieve top matches
  5. generate an answer grounded in retrieved chunks
- RAG reduces hallucinations, but only if you:
  - chunk well
  - retrieve well
  - cite/ground responses well

## Core concepts

### Why RAG exists

Context windows are finite and expensive. Even with huge context windows, brute-force “dump everything” is brittle:

- irrelevant context dilutes signal
- costs explode
- sensitive info can leak

RAG gives you **selective context**.

### The RAG pipeline (canonical)

1. **Ingest**
   - parse documents (PDF, HTML, markdown, etc.)
2. **Chunk**
   - split into retrievable units (ideally semantically coherent)
3. **Embed**
   - compute vector embeddings for each chunk
4. **Store**
   - save vectors + metadata in a vector DB
5. **Retrieve**
   - vector similarity search for top-K chunks
6. **Generate**
   - put retrieved chunks into the prompt and answer

### Chunking (the hidden lever)

Bad chunking leads to:

- missed retrieval
- incomplete answers
- weird context overlaps

Good chunking tries to preserve:

- semantic boundaries (headings/sections)
- enough surrounding context to understand a chunk
- metadata (source, section, date)

### Grounding and citations

A RAG answer should:

- use retrieved chunks explicitly
- avoid inventing details outside retrieved context
- cite sources (chunk metadata or doc IDs)

## Practical takeaways

- Use RAG whenever your agent needs knowledge beyond the prompt and recent conversation.
- Invest early in chunking + metadata; it dominates retrieval quality.
- Treat “retrieval quality” as something you can evaluate and iterate (later: eval chapters).
